# æ•°æ®åº“å¤„ç†ä»£ç å®¡è®¡æŠ¥å‘Š

> å®¡è®¡æ—¥æœŸ: 2026-02-05
> å®¡è®¡èŒƒå›´: SQLiteã€Milvus Liteã€KÃ¹zuDB ç›¸å…³ä»£ç 

## ä¸€ã€æ€»ä½“æ¶æ„æ¦‚è§ˆ

è¯¥é¡¹ç›®ä½¿ç”¨ä¸‰ç§æ•°æ®åº“æŠ€æœ¯ï¼š
- **SQLite** ([`backend/models/database.py`](../backend/models/database.py)) - å­˜å‚¨å…ƒæ•°æ®å’Œå…³ç³»æ•°æ®
- **Milvus Lite** ([`backend/memory/vector_store.py`](../backend/memory/vector_store.py)) - å‘é‡å­˜å‚¨å’Œæ£€ç´¢
- **KÃ¹zuDB** ([`backend/memory/graph_store.py`](../backend/memory/graph_store.py)) - å›¾æ•°æ®åº“å­˜å‚¨å®ä½“å…³ç³»

```mermaid
graph TD
    A[API Layer] --> B[MemoryService]
    A --> C[AutoMemoryService]
    B --> D[MemoryManager]
    B --> E[VectorStore]
    B --> F[GraphStore]
    C --> E
    C --> F
    D --> G[SQLite]
    E --> H[Milvus Lite]
    F --> I[KÃ¹zuDB]
```

---

## äºŒã€ä¸¥é‡å®‰å…¨é—®é¢˜

### 1. SQLæ³¨å…¥æ¼æ´ ğŸ”´ ä¸¥é‡

**ä½ç½®**: [`backend/memory/graph_store.py`](../backend/memory/graph_store.py)

æ‰€æœ‰SQLæŸ¥è¯¢ä½¿ç”¨f-stringç›´æ¥æ‹¼æ¥ï¼Œå­˜åœ¨SQLæ³¨å…¥é£é™©ï¼š

| æ–¹æ³• | è¡Œå· | é—®é¢˜ |
|------|------|------|
| `create_entity()` | 140-147 | ç›´æ¥æ‹¼æ¥nameã€typeã€description |
| `create_user()` | 172-175 | ç›´æ¥æ‹¼æ¥idã€name |
| `create_concept()` | 202-207 | ç›´æ¥æ‹¼æ¥nameã€description |
| `create_relation()` | 239-253 | ç›´æ¥æ‹¼æ¥from_entityã€to_entity |
| `create_mentions()` | 280-285 | ç›´æ¥æ‹¼æ¥user_idã€entity_name |
| `query_entity()` | 311-315 | ç›´æ¥æ‹¼æ¥entity_name |
| `update_entity_access()` | 384-387 | ç›´æ¥æ‹¼æ¥entity_name |

**å½±å“**: æ”»å‡»è€…å¯ä»¥é€šè¿‡æ„é€ æ¶æ„è¾“å…¥æ‰§è¡Œä»»æ„SQLè¯­å¥ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®æ³„éœ²ã€æ•°æ®ç¯¡æ”¹æˆ–æ•°æ®åº“è¢«ç ´åã€‚

**ä¿®å¤å»ºè®®**:

```python
# ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
async def create_entity(self, name: str, type: str, description: Optional[str] = None) -> bool:
    current_time = get_current_timestamp_ms()
    
    try:
        # ä½¿ç”¨KÃ¹zuDBçš„å‚æ•°åŒ–æŸ¥è¯¢è¯­æ³•
        self.conn.execute(
            f"MERGE (e:{settings.KUZU_NODE_TABLE_ENTITY} {{name: $name}}) "
            "ON CREATE SET e.type = $type, e.description = $description, "
            "e.created_at = $created_at, e.last_accessed_at = $last_accessed_at",
            {
                "name": name,
                "type": type,
                "description": description or "",
                "created_at": current_time,
                "last_accessed_at": current_time
            }
        )
        
        logger.debug(f"Created entity: name={name}, type={type}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to create entity: {e}")
        return False

# æˆ–è€…æ·»åŠ è¾“å…¥éªŒè¯å’Œè½¬ä¹‰
def _escape_string(value: str) -> str:
    """è½¬ä¹‰å­—ç¬¦ä¸²ä»¥é˜²æ­¢SQLæ³¨å…¥"""
    return value.replace("'", "''").replace("\\", "\\\\")
```

---

## ä¸‰ã€èµ„æºç®¡ç†é—®é¢˜

### 2. æ•°æ®åº“è¿æ¥æœªæ­£ç¡®å…³é—­ ğŸŸ  é«˜

**ä½ç½®**: 
- [`backend/memory/memory_manager.py:19-22`](../backend/memory/memory_manager.py:19-22)
- [`backend/services/memory_service.py:24-27`](../backend/services/memory_service.py:24-27)

```python
class MemoryManager:
    def __init__(self):
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨"""
        self.db = SessionLocal()  # åˆ›å»ºä¼šè¯ä½†æ²¡æœ‰æ˜ç¡®çš„å…³é—­æœºåˆ¶
        logger.info("MemoryManager initialized")
```

**å½±å“**: å¯èƒ½å¯¼è‡´è¿æ¥æ³„æ¼ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼‚å¸¸æƒ…å†µä¸‹ã€‚é•¿æ—¶é—´è¿è¡Œåå¯èƒ½è€—å°½æ•°æ®åº“è¿æ¥æ± èµ„æºã€‚

**ä¿®å¤å»ºè®®**:

```python
# æ–¹æ¡ˆ1: ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼ï¼ˆæ¨èï¼‰
from fastapi import Depends
from sqlalchemy.orm import Session

def get_db():
    """æ•°æ®åº“ä¼šè¯ä¾èµ–"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

class MemoryManager:
    def __init__(self, db: Session = Depends(get_db)):
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨"""
        self.db = db
        logger.info("MemoryManager initialized")

# æ–¹æ¡ˆ2: å®ç°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from contextlib import contextmanager

@contextmanager
def get_memory_manager():
    """è·å–è®°å¿†ç®¡ç†å™¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    db = SessionLocal()
    try:
        manager = MemoryManager()
        manager.db = db
        yield manager
    finally:
        db.close()
        logger.info("MemoryManager closed")

# ä½¿ç”¨ç¤ºä¾‹
async with get_memory_manager() as manager:
    memory = await manager.create_memory(...)
```

### 3. ä¸´æ—¶ä¼šè¯å¯èƒ½æœªæ­£ç¡®å…³é—­ ğŸŸ  é«˜

**ä½ç½®**: [`backend/memory/retrieval.py:248-273`](../backend/memory/retrieval.py:248-273)

```python
async def _enrich_with_event_time(self, results: List[Dict[str, Any]]):
    try:
        from models.database import SessionLocal, Memory
        db = SessionLocal()
        
        try:
            # æŸ¥è¯¢é€»è¾‘
            memories = db.query(Memory).filter(Memory.vector_id.in_(vector_ids)).all()
            # ...
        finally:
            db.close()  # åœ¨finallyä¸­å…³é—­ï¼Œè¿™æ˜¯å¥½çš„åšæ³•
```

**å½±å“**: è™½ç„¶ä½¿ç”¨äº†try-finallyï¼Œä½†å¦‚æœåœ¨æŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼Œå¯èƒ½ä»æœ‰èµ„æºæ³„æ¼é£é™©ã€‚

**ä¿®å¤å»ºè®®**: å½“å‰å®ç°å·²ç»è¾ƒå¥½ï¼Œä½†å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›ï¼š

```python
async def _enrich_with_event_time(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä»æ•°æ®åº“ä¸­è·å–event_timeä¿¡æ¯å¹¶æ·»åŠ åˆ°ç»“æœä¸­"""
    try:
        vector_ids = [result.get("id") for result in results]
        
        if not vector_ids:
            return results
        
        from models.database import SessionLocal, Memory
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿è¿æ¥å…³é—­
        with SessionLocal() as db:
            try:
                memories = db.query(Memory).filter(
                    Memory.vector_id.in_(vector_ids)
                ).all()
                
                event_time_map = {}
                for memory in memories:
                    event_time = getattr(memory, 'event_time', None)
                    if event_time is not None:
                        event_time_map[memory.vector_id] = event_time.isoformat()
                
                for result in results:
                    vector_id = result.get("id")
                    result["event_time"] = event_time_map.get(vector_id)
                
                logger.debug(f"Enriched {len(event_time_map)} results with event_time")
                
            except Exception as e:
                logger.warning(f"Failed to enrich results with event_time: {e}")
        
        return results
        
    except Exception as e:
        logger.warning(f"Failed to enrich results with event_time: {e}")
        return results
```

### 4. äº‹åŠ¡ç®¡ç†ä¸ä¸€è‡´ ğŸŸ  é«˜

**ä½ç½®**: [`backend/services/memory_service.py:170`](../backend/services/memory_service.py:170)

```python
async def update_memory(self, memory_id: str, memory_data: MemoryUpdate) -> Optional[Memory]:
    try:
        # ... æ›´æ–°é€»è¾‘ ...
        
        self.db.commit()  # ç›´æ¥æäº¤ï¼Œæ²¡æœ‰try-finallyä¿æŠ¤
        self.db.refresh(memory)
        
        return memory
        
    except Exception as e:
        self.db.rollback()  # å¼‚å¸¸æ—¶å›æ»š
        logger.error(f"Failed to update memory: {e}")
        return None
```

**å½±å“**: å¦‚æœåœ¨commitä¹‹åã€refreshä¹‹å‰å‘ç”Ÿå¼‚å¸¸ï¼Œæ•°æ®åº“çŠ¶æ€å¯èƒ½ä¸ä¸€è‡´ã€‚

**ä¿®å¤å»ºè®®**:

```python
async def update_memory(self, memory_id: str, memory_data: MemoryUpdate) -> Optional[Memory]:
    try:
        memory = await memory_manager.get_memory(memory_id)
        if not memory:
            return None

        # æ›´æ–°å†…å®¹
        if memory_data.content is not None:
            embedding = await embedding_client.embed(memory_data.content)

            await vector_store.update_vector(
                id=memory.vector_id,
                content=memory_data.content,
                embedding=embedding
            )

            memory.content = memory_data.content

            from utils.helpers import calculate_similarity_score, get_current_timestamp_ms
            new_score = calculate_similarity_score(
                similarity=1.0,
                access_count=memory.access_count,
                max_access_count=100,
                last_accessed_at=get_current_timestamp_ms(),
                created_at=int(memory.created_at.timestamp() * 1000),
                lambda_decay=0.0001,
                graph_score=0.0
            )
            memory.score = new_score

        if memory_data.metadata is not None:
            memory.set_metadata(memory_data.metadata)

        # ä½¿ç”¨try-finallyç¡®ä¿äº‹åŠ¡æ­£ç¡®å¤„ç†
        try:
            self.db.commit()
            self.db.refresh(memory)
        except Exception as commit_error:
            self.db.rollback()
            raise commit_error

        logger.info(f"Updated memory: id={memory_id}, score={memory.score}")
        return memory

    except Exception as e:
        self.db.rollback()
        logger.error(f"Failed to update memory: {e}")
        return None
```

---

## å››ã€æ•°æ®ä¸€è‡´æ€§é—®é¢˜

### 5. è·¨æ•°æ®åº“æ“ä½œç¼ºä¹äº‹åŠ¡ä¿æŠ¤ ğŸŸ  é«˜

**ä½ç½®**: [`backend/services/memory_service.py:29-99`](../backend/services/memory_service.py:29-99)

```python
async def create_memory(self, memory_data: MemoryCreate, content: str, event_time: Optional[datetime] = None):
    try:
        # 1. å°†å†…å®¹è½¬æ¢ä¸ºå‘é‡
        embedding = await embedding_client.embed(content)

        # 2. æ’å…¥å‘é‡å­˜å‚¨
        vector_id = generate_id()
        success = await vector_store.insert_knowledge(
            id=vector_id,
            persona_id=memory_data.persona_id,
            content=content,
            embedding=embedding,
            entity_id=memory_data.entity_id,
            metadata=memory_data.metadata
        )

        # 3. å¦‚æœæœ‰å®ä½“IDï¼Œåˆ›å»ºæˆ–æ›´æ–°å›¾è°±èŠ‚ç‚¹
        if memory_data.entity_id:
            await graph_store.create_entity(
                name=memory_data.entity_id,
                type="default",
                description=content[:200]
            )

            # æå–å¹¶åˆ›å»ºå®ä½“å…³ç³»
            entities = extract_entities(content)
            for entity in entities:
                if entity != memory_data.entity_id:
                    await graph_store.create_relation(
                        from_entity=memory_data.entity_id,
                        to_entity=entity,
                        relation_type="RELATED_TO",
                        weight=1.0
                    )

        if not success:
            raise Exception("Failed to insert vector")

        # 4. åˆ›å»ºè®°å¿†è®°å½•
        memory = await memory_manager.create_memory(
            vector_id=vector_id,
            persona_id=memory_data.persona_id,
            content=content,
            type=memory_data.type,
            entity_id=memory_data.entity_id,
            metadata=memory_data.metadata,
            event_time=event_time
        )

        return memory
    except Exception as e:
        logger.error(f"Failed to create memory: {e}")
        return None
```

**å½±å“**: 
- å¦‚æœç¬¬3æ­¥ï¼ˆå›¾è°±æ“ä½œï¼‰å¤±è´¥ï¼Œç¬¬2æ­¥ï¼ˆå‘é‡å­˜å‚¨ï¼‰çš„æ•°æ®å·²ç»å†™å…¥ä½†æ— æ³•å›æ»š
- å¦‚æœç¬¬4æ­¥ï¼ˆSQLiteï¼‰å¤±è´¥ï¼Œå‘é‡å­˜å‚¨å’Œå›¾è°±æ•°æ®éƒ½ä¼šæˆä¸ºå­¤ç«‹æ•°æ®
- æ•°æ®ä¸ä¸€è‡´å¯èƒ½å¯¼è‡´æ£€ç´¢ç»“æœä¸å‡†ç¡®

**ä¿®å¤å»ºè®®**:

```python
async def create_memory(
    self,
    memory_data: MemoryCreate,
    content: str,
    event_time: Optional[datetime] = None
) -> Optional[Memory]:
    """
    åˆ›å»ºè®°å¿†ï¼ˆå¸¦äº‹åŠ¡ä¿æŠ¤ï¼‰
    """
    embedding = None
    vector_id = None
    memory = None
    
    try:
        # 1. å°†å†…å®¹è½¬æ¢ä¸ºå‘é‡
        embedding = await embedding_client.embed(content)
        
        # 2. æ’å…¥å‘é‡å­˜å‚¨
        vector_id = generate_id()
        success = await vector_store.insert_knowledge(
            id=vector_id,
            persona_id=memory_data.persona_id,
            content=content,
            embedding=embedding,
            entity_id=memory_data.entity_id,
            metadata=memory_data.metadata
        )
        
        if not success:
            raise Exception("Failed to insert vector")
        
        # 3. åˆ›å»ºå›¾è°±èŠ‚ç‚¹å’Œå…³ç³»
        if memory_data.entity_id:
            await graph_store.create_entity(
                name=memory_data.entity_id,
                type="default",
                description=content[:200]
            )
            
            entities = extract_entities(content)
            for entity in entities:
                if entity != memory_data.entity_id:
                    await graph_store.create_relation(
                        from_entity=memory_data.entity_id,
                        to_entity=entity,
                        relation_type="RELATED_TO",
                        weight=1.0
                    )
        
        # 4. åˆ›å»ºè®°å¿†è®°å½•
        memory = await memory_manager.create_memory(
            vector_id=vector_id,
            persona_id=memory_data.persona_id,
            content=content,
            type=memory_data.type,
            entity_id=memory_data.entity_id,
            metadata=memory_data.metadata,
            event_time=event_time
        )
        
        if not memory:
            raise Exception("Failed to create memory record")
        
        logger.info(f"Created memory: id={memory.id}, type={memory_data.type}")
        return memory
        
    except Exception as e:
        # å›æ»šå·²æ‰§è¡Œçš„æ“ä½œ
        logger.error(f"Failed to create memory, rolling back: {e}")
        
        # å›æ»šå‘é‡å­˜å‚¨
        if vector_id:
            try:
                await vector_store.delete_vector(vector_id)
                logger.info(f"Rolled back vector: {vector_id}")
            except Exception as rollback_error:
                logger.error(f"Failed to rollback vector: {rollback_error}")
        
        # å›æ»šå›¾è°±æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if memory_data.entity_id:
            try:
                # KÃ¹zuDBå¯èƒ½ä¸æ”¯æŒåˆ é™¤ï¼Œè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µå¤„ç†
                logger.warning(f"Graph data rollback not implemented for entity: {memory_data.entity_id}")
            except Exception as rollback_error:
                logger.error(f"Failed to rollback graph data: {rollback_error}")
        
        return None
```

### 6. åˆ é™¤æ“ä½œæ•°æ®ä¸åŒæ­¥ ğŸŸ¡ ä¸­

**ä½ç½®**: [`backend/services/memory_service.py:181-208`](../backend/services/memory_service.py:181-208)

```python
async def delete_memory(self, memory_id: str) -> bool:
    try:
        # è·å–è®°å¿†
        memory = await memory_manager.get_memory(memory_id)
        if not memory:
            return False

        # åˆ é™¤å‘é‡å­˜å‚¨ä¸­çš„æ•°æ®
        await vector_store.delete_vector(memory.vector_id)

        # åˆ é™¤è®°å¿†è®°å½•
        success = await memory_manager.delete_memory(memory_id)

        logger.info(f"Deleted memory: id={memory_id}, success={success}")
        return success

    except Exception as e:
        logger.error(f"Failed to delete memory: {e}")
        return False
```

**å½±å“**: 
- å¦‚æœå‘é‡åˆ é™¤æˆåŠŸä½†æ•°æ®åº“åˆ é™¤å¤±è´¥ï¼Œæ•°æ®ä¸ä¸€è‡´
- å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»æ²¡æœ‰è¢«åˆ é™¤ï¼Œå¯¼è‡´å­¤ç«‹æ•°æ®

**ä¿®å¤å»ºè®®**:

```python
async def delete_memory(self, memory_id: str) -> bool:
    """
    åˆ é™¤è®°å¿†ï¼ˆå¸¦å®Œæ•´æ¸…ç†ï¼‰
    """
    try:
        # è·å–è®°å¿†
        memory = await memory_manager.get_memory(memory_id)
        if not memory:
            return False

        vector_id = memory.vector_id
        entity_id = memory.entity_id
        
        # 1. åˆ é™¤å‘é‡å­˜å‚¨ä¸­çš„æ•°æ®
        vector_deleted = await vector_store.delete_vector(vector_id)
        if not vector_deleted:
            logger.warning(f"Failed to delete vector: {vector_id}")
        
        # 2. åˆ é™¤å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if entity_id:
            try:
                # æ³¨æ„ï¼šKÃ¹zuDBçš„åˆ é™¤è¯­æ³•éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                # è¿™é‡Œå‡è®¾æœ‰delete_entityæ–¹æ³•
                await graph_store.delete_entity(entity_id)
                logger.info(f"Deleted graph entity: {entity_id}")
            except Exception as graph_error:
                logger.warning(f"Failed to delete graph entity: {graph_error}")
        
        # 3. åˆ é™¤è®°å¿†è®°å½•
        success = await memory_manager.delete_memory(memory_id)
        
        if success:
            logger.info(f"Deleted memory: id={memory_id}")
        else:
            # å¦‚æœæ•°æ®åº“åˆ é™¤å¤±è´¥ï¼Œå°è¯•å›æ»šå‘é‡åˆ é™¤
            logger.error(f"Failed to delete memory record, attempting rollback")
            try:
                # é‡æ–°æ’å…¥å‘é‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                # å®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„æ¢å¤é€»è¾‘
                pass
            except Exception as rollback_error:
                logger.error(f"Rollback failed: {rollback_error}")
        
        return success

    except Exception as e:
        logger.error(f"Failed to delete memory: {e}")
        return False
```

---

## äº”ã€å¹¶å‘å®‰å…¨é—®é¢˜

### 7. æ‡’åŠ è½½å…¨å±€å®ä¾‹éçº¿ç¨‹å®‰å…¨ ğŸŸ¡ ä¸­

**ä½ç½®**: æ‰€æœ‰æ‡’åŠ è½½å‡½æ•°

| æ–‡ä»¶ | æ–¹æ³• | è¡Œå· |
|------|------|------|
| `graph_store.py` | `get_graph_store()` | 409-414 |
| `vector_store.py` | `get_vector_store()` | 330-335 |
| `memory_manager.py` | `get_memory_manager()` | 246-251 |
| `memory_service.py` | `get_memory_service()` | 284-289 |
| `auto_memory_service.py` | `get_auto_memory_service()` | 278-283 |

```python
def get_graph_store() -> GraphStore:
    """è·å–å›¾è°±å­˜å‚¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _graph_store
    if _graph_store is None:
        _graph_store = GraphStore()  # ç«æ€æ¡ä»¶
    return _graph_store
```

**å½±å“**: åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œå¤šä¸ªçº¿ç¨‹å¯èƒ½åŒæ—¶æ£€æŸ¥ `_graph_store is None` å¹¶åˆ›å»ºå¤šä¸ªå®ä¾‹ï¼Œå¯¼è‡´èµ„æºæµªè´¹å’Œæ½œåœ¨çš„æ•°æ®ç«äº‰ã€‚

**ä¿®å¤å»ºè®®**:

```python
import threading

# æ–¹æ¡ˆ1: ä½¿ç”¨çº¿ç¨‹é”
_graph_store = None
_graph_store_lock = threading.Lock()

def get_graph_store() -> GraphStore:
    """è·å–å›¾è°±å­˜å‚¨å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨çš„æ‡’åŠ è½½ï¼‰"""
    global _graph_store
    if _graph_store is None:
        with _graph_store_lock:
            if _graph_store is None:  # åŒé‡æ£€æŸ¥é”å®š
                _graph_store = GraphStore()
    return _graph_store

# æ–¹æ¡ˆ2: ä½¿ç”¨å•ä¾‹è£…é¥°å™¨
def singleton(cls):
    """å•ä¾‹è£…é¥°å™¨"""
    instances = {}
    instances_lock = threading.Lock()
    
    def get_instance(*args, **kwargs):
        if cls not in instances:
            with instances_lock:
                if cls not in instances:
                    instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    
    return get_instance

@singleton
class GraphStore:
    # ... åŸæœ‰ä»£ç  ...
    pass

# æ–¹æ¡ˆ3: ä½¿ç”¨æ¨¡å—çº§åˆå§‹åŒ–ï¼ˆæ¨èç”¨äºç®€å•åœºæ™¯ï¼‰
# åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–ï¼Œé¿å…æ‡’åŠ è½½
_graph_store = GraphStore()

def get_graph_store() -> GraphStore:
    return _graph_store
```

---

## å…­ã€æ€§èƒ½é—®é¢˜

### 8. N+1æŸ¥è¯¢é—®é¢˜ ğŸŸ¡ ä¸­

**ä½ç½®**: [`backend/memory/retrieval.py:148-191`](../backend/memory/retrieval.py:148-191)

```python
async def _enhance_with_graph(
    self,
    results: List[Dict[str, Any]],
    query_text: str
) -> List[Dict[str, Any]]:
    enhanced_results = []

    for result in results:
        entity_id = result.get("entity_id")
        if not entity_id:
            enhanced_results.append(result)
            continue

        try:
            # å¯¹æ¯ä¸ªç»“æœéƒ½è°ƒç”¨ä¸€æ¬¡æŸ¥è¯¢ - N+1é—®é¢˜
            graph_data = await graph_store.query_entity(
                entity_name=entity_id,
                max_depth=2
            )

            graph_score = self._calculate_graph_score(graph_data)

            result["graph_data"] = graph_data
            result["graph_score"] = graph_score

            enhanced_results.append(result)

        except Exception as e:
            logger.warning(f"Failed to enhance result with graph: {e}")
            enhanced_results.append(result)

    return enhanced_results
```

**å½±å“**: å¦‚æœæœ‰10ä¸ªæ£€ç´¢ç»“æœï¼Œä¼šæ‰§è¡Œ10æ¬¡å›¾è°±æŸ¥è¯¢ï¼Œä¸¥é‡å½±å“æ€§èƒ½ã€‚

**ä¿®å¤å»ºè®®**:

```python
async def _enhance_with_graph(
    self,
    results: List[Dict[str, Any]],
    query_text: str
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨å›¾è°±ä¿¡æ¯å¢å¼ºæ£€ç´¢ç»“æœï¼ˆæ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–ï¼‰
    """
    enhanced_results = []
    
    # 1. æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„entity_id
    entity_ids = set()
    for result in results:
        entity_id = result.get("entity_id")
        if entity_id:
            entity_ids.add(entity_id)
    
    # 2. æ‰¹é‡æŸ¥è¯¢å›¾è°±æ•°æ®
    graph_data_map = {}
    if entity_ids:
        try:
            # æ–¹æ¡ˆA: å¦‚æœKÃ¹zuDBæ”¯æŒæ‰¹é‡æŸ¥è¯¢
            # graph_data_map = await graph_store.batch_query_entities(list(entity_ids))
            
            # æ–¹æ¡ˆB: ä½¿ç”¨å¹¶å‘æŸ¥è¯¢
            import asyncio
            query_tasks = [
                graph_store.query_entity(entity_name=entity_id, max_depth=2)
                for entity_id in entity_ids
            ]
            query_results = await asyncio.gather(*query_tasks, return_exceptions=True)
            
            for entity_id, result in zip(entity_ids, query_results):
                if isinstance(result, Exception):
                    logger.warning(f"Failed to query entity {entity_id}: {result}")
                else:
                    graph_data_map[entity_id] = result
                    
        except Exception as e:
            logger.warning(f"Failed to batch query graph data: {e}")
    
    # 3. å°†å›¾è°±æ•°æ®æ·»åŠ åˆ°ç»“æœä¸­
    for result in results:
        entity_id = result.get("entity_id")
        if entity_id and entity_id in graph_data_map:
            graph_data = graph_data_map[entity_id]
            graph_score = self._calculate_graph_score(graph_data)
            result["graph_data"] = graph_data
            result["graph_score"] = graph_score
        else:
            result["graph_data"] = {"nodes": [], "edges": []}
            result["graph_score"] = 0.0
        
        enhanced_results.append(result)

    return enhanced_results
```

### 9. ç¼ºå°‘å¤åˆç´¢å¼• ğŸŸ¡ ä¸­

**ä½ç½®**: [`backend/models/database.py:37-52`](../backend/models/database.py:37-52)

```python
class Memory(Base):
    id = Column(String, primary_key=True, index=True)
    persona_id = Column(String, ForeignKey("personas.id"), nullable=False, index=True)
    vector_id = Column(String, nullable=False, index=True)
    entity_id = Column(String, nullable=True, index=True)
    type = Column(String, nullable=False)
    content = Column(Text, nullable=False)
    # ...
```

**å½±å“**: å¸¸è§çš„æŸ¥è¯¢æ¨¡å¼å¦‚ `WHERE persona_id = ? AND type = ?` å¯èƒ½éœ€è¦å¤åˆç´¢å¼•ä¼˜åŒ–ï¼Œå¦åˆ™ä¼šå¯¼è‡´å…¨è¡¨æ‰«æã€‚

**ä¿®å¤å»ºè®®**:

```python
from sqlalchemy import Index

class Memory(Base):
    """è®°å¿†è¡¨ - ç”¨äºè¿½è¸ªè®°å¿†çš„å…ƒæ•°æ®"""
    __tablename__ = "memories"
    
    id = Column(String, primary_key=True, index=True)
    persona_id = Column(String, ForeignKey("personas.id"), nullable=False, index=True)
    vector_id = Column(String, nullable=False, index=True)
    entity_id = Column(String, nullable=True, index=True)
    type = Column(String, nullable=False, index=True)
    content = Column(Text, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow, index=True)
    event_time = Column(DateTime, nullable=True, index=True)
    last_accessed_at = Column(DateTime, default=datetime.utcnow, index=True)
    access_count = Column(Integer, default=0)
    score = Column(Float, default=0.0)
    meta_data = Column(Text, nullable=True)
    
    # æ·»åŠ å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_persona_type', 'persona_id', 'type'),
        Index('idx_persona_created', 'persona_id', 'created_at'),
        Index('idx_vector_entity', 'vector_id', 'entity_id'),
        Index('idx_event_time_persona', 'event_time', 'persona_id'),
    )
```

---

## ä¸ƒã€é”™è¯¯å¤„ç†é—®é¢˜

### 10. å¼‚å¸¸æ•è·è¿‡äºå®½æ³› ğŸŸ¡ ä¸­

**ä½ç½®**: å¤šå¤„ä½¿ç”¨ `except Exception as e`

**å½±å“**: æ•è·æ‰€æœ‰å¼‚å¸¸ä¼šæ©ç›–çœŸæ­£çš„é”™è¯¯ï¼Œä¸åˆ©äºè°ƒè¯•å’Œé—®é¢˜å®šä½ã€‚

**ä¿®å¤å»ºè®®**:

```python
# ä¸å¥½çš„åšæ³•
except Exception as e:
    logger.error(f"Failed to create memory: {e}")
    return None

# å¥½çš„åšæ³•
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
from pymilvus.exceptions import MilvusException

async def create_memory(self, memory_data: MemoryCreate, content: str, event_time: Optional[datetime] = None):
    try:
        # ... ä¸šåŠ¡é€»è¾‘ ...
    except IntegrityError as e:
        logger.error(f"Database integrity error: {e}")
        # å¤„ç†å”¯ä¸€é”®å†²çªç­‰
        return None
    except SQLAlchemyError as e:
        logger.error(f"Database error: {e}")
        # å¤„ç†å…¶ä»–æ•°æ®åº“é”™è¯¯
        return None
    except MilvusException as e:
        logger.error(f"Vector store error: {e}")
        # å¤„ç†å‘é‡å­˜å‚¨é”™è¯¯
        return None
    except ValueError as e:
        logger.error(f"Invalid input: {e}")
        # å¤„ç†è¾“å…¥éªŒè¯é”™è¯¯
        return None
    except Exception as e:
        logger.error(f"Unexpected error in create_memory: {e}", exc_info=True)
        # è®°å½•å®Œæ•´çš„å †æ ˆè·Ÿè¸ª
        return None
```

### 11. JSONè§£æå¤±è´¥é™é»˜è·³è¿‡ ğŸŸ¡ ä¸­

**ä½ç½®**: [`backend/services/auto_memory_service.py:259-267`](../backend/services/auto_memory_service.py:259-267)

```python
except json.JSONDecodeError:
    logger.warning(f"Failed to parse extraction result as JSON: {result[:100]}")
    logger.warning("Skipping memory extraction due to JSON parse error")
    return {
        "memories": [],
        "entities": [],
        "relations": []
    }
```

**å½±å“**: JSONè§£æå¤±è´¥æ—¶é™é»˜è·³è¿‡ï¼Œç”¨æˆ·ä¸çŸ¥é“è®°å¿†æå–å¤±è´¥ï¼Œå¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯ã€‚

**ä¿®å¤å»ºè®®**:

```python
def _parse_extraction_result(self, result: str) -> Dict[str, Any]:
    """
    è§£æLLMæå–ç»“æœ
    """
    import json

    try:
        data = json.loads(result)
        
        # éªŒè¯æ•°æ®ç»“æ„
        if not isinstance(data, dict):
            raise ValueError("Result is not a dictionary")
        
        required_keys = ["memories", "entities", "relations"]
        for key in required_keys:
            if key not in data:
                raise ValueError(f"Missing required key: {key}")
            if not isinstance(data[key], list):
                raise ValueError(f"Key '{key}' is not a list")
        
        return {
            "memories": data.get("memories", []),
            "entities": data.get("entities", []),
            "relations": data.get("relations", [])
        }

    except json.JSONDecodeError as e:
        logger.error(f"JSON parse error: {e}")
        logger.error(f"Raw result: {result[:500]}")
        # å¯ä»¥è€ƒè™‘é‡è¯•æˆ–ä½¿ç”¨å¤‡ç”¨è§£æç­–ç•¥
        return {
            "memories": [],
            "entities": [],
            "relations": [],
            "parse_error": str(e)
        }
    except ValueError as e:
        logger.error(f"Validation error: {e}")
        return {
            "memories": [],
            "entities": [],
            "relations": [],
            "validation_error": str(e)
        }
```

---

## å…«ã€ä»£ç è´¨é‡é—®é¢˜

### 12. é‡å¤çš„æ•°æ®åº“ä¼šè¯åˆ›å»º ğŸŸ¢ ä½

**ä½ç½®**: 
- [`backend/services/memory_service.py:26`](../backend/services/memory_service.py:26)
- [`backend/memory/memory_manager.py:21`](../backend/memory/memory_manager.py:21)

**å½±å“**: ä¸¤ä¸ªç±»éƒ½åˆ›å»ºäº†è‡ªå·±çš„æ•°æ®åº“ä¼šè¯ï¼Œå¯èƒ½å¯¼è‡´èµ„æºæµªè´¹å’Œä¼šè¯ç®¡ç†æ··ä¹±ã€‚

**ä¿®å¤å»ºè®®**: ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼ï¼Œå…±äº«åŒä¸€ä¸ªæ•°æ®åº“ä¼šè¯ã€‚

### 13. ç¼ºå°‘è¾“å…¥éªŒè¯ ğŸŸ¢ ä½

**ä½ç½®**: [`backend/memory/graph_store.py`](../backend/memory/graph_store.py) çš„æ‰€æœ‰æ–¹æ³•

**å½±å“**: æ²¡æœ‰éªŒè¯è¾“å…¥å‚æ•°ï¼ˆå¦‚ç©ºå­—ç¬¦ä¸²ã€è¶…é•¿å­—ç¬¦ä¸²ç­‰ï¼‰ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®åº“é”™è¯¯æˆ–æ€§èƒ½é—®é¢˜ã€‚

**ä¿®å¤å»ºè®®**:

```python
def _validate_entity_name(self, name: str) -> bool:
    """éªŒè¯å®ä½“åç§°"""
    if not name or not isinstance(name, str):
        return False
    if len(name) > 100:  # é™åˆ¶é•¿åº¦
        return False
    # æ£€æŸ¥éæ³•å­—ç¬¦
    if any(c in name for c in ['"', "'", '\\', ';']):
        return False
    return True

async def create_entity(self, name: str, type: str, description: Optional[str] = None) -> bool:
    """åˆ›å»ºå®ä½“èŠ‚ç‚¹"""
    # è¾“å…¥éªŒè¯
    if not self._validate_entity_name(name):
        logger.error(f"Invalid entity name: {name}")
        return False
    
    if not type or not isinstance(type, str):
        logger.error(f"Invalid entity type: {type}")
        return False
    
    if description and len(description) > 1000:
        logger.warning(f"Description too long, truncating: {len(description)}")
        description = description[:1000]
    
    # ... åŸæœ‰é€»è¾‘ ...
```

### 14. æ—¶é—´å¤„ç†ä¸ä¸€è‡´ ğŸŸ¢ ä½

**ä½ç½®**: ä»£ç ä¸­ä½¿ç”¨äº†ä¸¤ç§ä¸åŒçš„æ—¶é—´è¡¨ç¤ºæ–¹å¼

| æ•°æ®åº“/å­˜å‚¨ | æ–‡ä»¶ | æ—¶é—´æ ¼å¼ | å­—æ®µç±»å‹ |
|------------|------|----------|----------|
| SQLite | [`backend/models/database.py:33-34,47-49`](../backend/models/database.py:33-34) | `datetime.utcnow()` | DateTime |
| Milvus | [`backend/memory/vector_store.py:129,236`](../backend/memory/vector_store.py:129) | `get_current_timestamp_ms()` | INT64 |
| KÃ¹zuDB | [`backend/memory/graph_store.py:137,199,235,277,381`](../backend/memory/graph_store.py:137) | `get_current_timestamp_ms()` | INT64 |

**æ–¹å¼å¯¹æ¯”**:

```python
# æ–¹å¼1: datetime.utcnow() - è¿”å›datetimeå¯¹è±¡
from datetime import datetime
created_at = datetime.utcnow()  # ä¾‹å¦‚: datetime(2026,2,5,4,16,5)

# æ–¹å¼2: time.time() * 1000 - è¿”å›æ¯«ç§’æ—¶é—´æˆ³ï¼ˆæ•´æ•°ï¼‰
import time
timestamp = int(time.time() * 1000)  # ä¾‹å¦‚: 1738728965000
```

**å½±å“**:

1. **æ•°æ®è½¬æ¢å¼€é”€**
   ```python
   # memory_service.py:160 - éœ€è¦å°†datetimeè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
   created_at=int(memory.created_at.timestamp() * 1000)
   ```

2. **æ—¶åŒºå¤„ç†ä¸ä¸€è‡´**
   - `datetime.utcnow()` è¿”å›çš„æ˜¯æ— æ—¶åŒºä¿¡æ¯çš„datetimeå¯¹è±¡
   - `time.time()` è¿”å›çš„æ˜¯UTCæ—¶é—´æˆ³
   - å®¹æ˜“åœ¨æ—¶åŒºè½¬æ¢æ—¶å‡ºé”™

3. **ä»£ç å¯è¯»æ€§å·®**
   - å¼€å‘è€…éœ€è¦è®°ä½å“ªä¸ªåœ°æ–¹ç”¨å“ªç§æ ¼å¼
   - å®¹æ˜“æ··æ·†å¯¼è‡´bug

4. **è·¨æ•°æ®åº“åŒæ­¥å›°éš¾**
   - SQLiteå­˜å‚¨datetimeå¯¹è±¡
   - Milvuså’ŒKÃ¹zuDBå­˜å‚¨æ¯«ç§’æ—¶é—´æˆ³
   - æ•°æ®åŒæ­¥æ—¶éœ€è¦é¢‘ç¹è½¬æ¢

5. **æ—¶é—´è®¡ç®—é”™è¯¯é£é™©**
   - ä¸åŒæ ¼å¼æ··åˆä½¿ç”¨å¯èƒ½å¯¼è‡´æ—¶é—´å·®è®¡ç®—é”™è¯¯
   - åœ¨è¯„åˆ†è®¡ç®—ç­‰åœºæ™¯ä¸­å¯èƒ½äº§ç”Ÿä¸æ­£ç¡®çš„ç»“æœ

**ä¿®å¤å»ºè®®**:

```python
from datetime import datetime, timezone

# ç»Ÿä¸€æ—¶é—´è·å–å‡½æ•°
def get_current_datetime() -> datetime:
    """è·å–å½“å‰æ—¶é—´ï¼ˆå¸¦æ—¶åŒºï¼‰"""
    return datetime.now(timezone.utc)

def datetime_to_ms(dt: datetime) -> int:
    """å°†datetimeè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³"""
    return int(dt.timestamp() * 1000)

def ms_to_datetime(ms: int) -> datetime:
    """å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetime"""
    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc)
```

**å®æ–½æ­¥éª¤**:

1. åœ¨æ‰€æœ‰ä»£ç ä¸­ç»Ÿä¸€ä½¿ç”¨ `get_current_datetime()` è·å–å½“å‰æ—¶é—´
2. SQLiteæ•°æ®åº“ç»§ç»­ä½¿ç”¨DateTimeç±»å‹å­˜å‚¨datetimeå¯¹è±¡
3. Milvuså’ŒKÃ¹zuDBåœ¨å­˜å‚¨å‰ä½¿ç”¨ `datetime_to_ms()` è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
4. ä»Milvus/KÃ¹zuDBè¯»å–æ—¶ä½¿ç”¨ `ms_to_datetime()` è½¬æ¢å›datetimeå¯¹è±¡
5. åœ¨è®¡ç®—æ—¶é—´å·®ç­‰æ“ä½œæ—¶ç»Ÿä¸€ä½¿ç”¨datetimeå¯¹è±¡

---

## ä¹ã€ä¿®å¤ä¼˜å…ˆçº§å»ºè®®

| ä¼˜å…ˆçº§ | é—®é¢˜ç¼–å· | é—®é¢˜æè¿° | å½±å“ | é¢„è®¡å·¥ä½œé‡ |
|--------|----------|----------|------|------------|
| P0 | 1 | SQLæ³¨å…¥æ¼æ´ | å®‰å…¨é£é™© | 2-3å¤© |
| P1 | 5 | è·¨æ•°æ®åº“äº‹åŠ¡ | æ•°æ®ä¸€è‡´æ€§ | 3-5å¤© |
| P1 | 2 | è¿æ¥æ³„æ¼ | èµ„æºè€—å°½ | 2-3å¤© |
| P2 | 7 | å¹¶å‘å®‰å…¨ | çº¿ç¨‹å®‰å…¨ | 1-2å¤© |
| P2 | 6 | å›¾è°±æ•°æ®åŒæ­¥ | æ•°æ®ä¸€è‡´æ€§ | 2-3å¤© |
| P3 | 8 | N+1æŸ¥è¯¢ | æ€§èƒ½ | 1-2å¤© |
| P3 | 9 | ç¼ºå°‘å¤åˆç´¢å¼• | æ€§èƒ½ | 0.5å¤© |
| P4 | 10 | å¼‚å¸¸å¤„ç† | å¯ç»´æŠ¤æ€§ | 2-3å¤© |
| P4 | 11 | JSONè§£æ | ç”¨æˆ·ä½“éªŒ | 1å¤© |
| P4 | 12-14 | ä»£ç è´¨é‡ | å¯ç»´æŠ¤æ€§ | 1-2å¤© |

---

## åã€åç»­æ”¹è¿›å»ºè®®

### 10.1 æ·»åŠ å•å…ƒæµ‹è¯•

ä¸ºæ‰€æœ‰æ•°æ®åº“æ“ä½œæ·»åŠ å•å…ƒæµ‹è¯•ï¼Œç‰¹åˆ«æ˜¯ï¼š
- SQLæ³¨å…¥é˜²æŠ¤æµ‹è¯•
- äº‹åŠ¡å›æ»šæµ‹è¯•
- å¹¶å‘å®‰å…¨æµ‹è¯•
- è¾¹ç•Œæ¡ä»¶æµ‹è¯•

### 10.2 æ·»åŠ ç›‘æ§å’Œå‘Šè­¦

- æ•°æ®åº“è¿æ¥æ± ç›‘æ§
- æ…¢æŸ¥è¯¢ç›‘æ§
- å¼‚å¸¸ç»Ÿè®¡å’Œå‘Šè­¦

### 10.3 æ–‡æ¡£å®Œå–„

- æ·»åŠ APIæ–‡æ¡£
- æ·»åŠ æ•°æ®åº“æ¶æ„æ–‡æ¡£
- æ·»åŠ æ•…éšœæ’æŸ¥æŒ‡å—

### 10.4 ä»£ç å®¡æŸ¥æµç¨‹

å»ºç«‹ä»£ç å®¡æŸ¥æµç¨‹ï¼Œç¡®ä¿ï¼š
- æ‰€æœ‰æ•°æ®åº“æ“ä½œéƒ½ç»è¿‡å®¡æŸ¥
- å®‰å…¨é—®é¢˜è¢«åŠæ—¶å‘ç°
- æ€§èƒ½é—®é¢˜è¢«ä¼˜åŒ–

---

## é™„å½•ï¼šç›¸å…³æ–‡ä»¶æ¸…å•

| æ–‡ä»¶è·¯å¾„ | ä¸»è¦åŠŸèƒ½ |
|----------|----------|
| [`backend/models/database.py`](../backend/models/database.py) | SQLiteæ•°æ®åº“æ¨¡å‹å®šä¹‰ |
| [`backend/memory/graph_store.py`](../backend/memory/graph_store.py) | KÃ¹zuDBå›¾æ•°æ®åº“æ“ä½œ |
| [`backend/memory/vector_store.py`](../backend/memory/vector_store.py) | Milvuså‘é‡å­˜å‚¨æ“ä½œ |
| [`backend/memory/memory_manager.py`](../backend/memory/memory_manager.py) | è®°å¿†ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| [`backend/services/memory_service.py`](../backend/services/memory_service.py) | è®°å¿†CRUDæœåŠ¡ |
| [`backend/services/auto_memory_service.py`](../backend/services/auto_memory_service.py) | è‡ªåŠ¨è®°å¿†æå–æœåŠ¡ |
| [`backend/memory/retrieval.py`](../backend/memory/retrieval.py) | è®°å¿†æ£€ç´¢ç­–ç•¥ |
| [`backend/api/memory.py`](../backend/api/memory.py) | è®°å¿†ç®¡ç†API |
| [`backend/utils/helpers.py`](../backend/utils/helpers.py) | è¾…åŠ©å‡½æ•° |
